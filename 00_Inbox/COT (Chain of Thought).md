**CoT(Chain of Thought, 생각의 사슬)**는 거대 언어 모델(LLM)이 복잡한 문제를 해결할 때, 정답을 바로 내놓는 대신 **중간 추론 과정을 단계별로 생성하도록 유도하는 프롬프트 엔지니어링 기법**입니다.

사람이 어려운 수학 문제를 풀 때 머릿속으로 단계별 계산을 거치는 것과 유사한 방식을 AI에게 적용한 것이라 이해하면 쉽습니다.

---

## 1. CoT의 핵심 원리

기존의 일반적인 프롬프트 방식(Few-shot)은 질문과 정답의 쌍만 보여주지만, **CoT는 "질문 - 추론 과정 - 정답"의 구조**를 보여줍니다.

- **일반적인 방식:** "사과가 5개 있고 2개를 먹었어. 남은 건? 답: 3개"
    
- **CoT 방식:** "사과가 5개 있고 2개를 먹었어. **처음에 5개가 있었는데 2개를 뺏으니까 $5 - 2 = 3$이 돼.** 답: 3개"
    

이처럼 중간 논리 단계를 거치면 모델은 훨씬 복잡한 논리 구조나 산술 문제를 더 정확하게 해결할 수 있게 됩니다.

---

## 2. 주요 유형

### ① Few-shot CoT

사용자가 프롬프트에 **추론 과정이 포함된 예시(Example)**를 몇 개 직접 작성해서 보여주는 방식입니다. 모델은 이 예시의 형식을 따라하며 논리적으로 사고하기 시작합니다.

### ② Zero-shot CoT (모두가 아는 그 문장)

예시를 들 필요도 없이, 질문 끝에 **"단계별로 차근차근 생각해봐(Let's think step by step)"**라는 문구만 추가하는 방식입니다. 이 간단한 명령만으로도 LLM은 내부적으로 추론 단계를 생성하며 정답률이 비약적으로 상승합니다.

---

## 3. CoT가 왜 중요한가요?

- **복잡한 문제 해결:** 단순 암기나 지식 인출을 넘어 산술, 상식적 추론, 상징적 조작(Symbolic reasoning) 등에서 강력한 성능을 발휘합니다.
    
- **해석 가능성(Explainability):** AI가 왜 이런 결론에 도달했는지 그 과정을 텍스트로 보여주기 때문에 결과의 신뢰도를 판단하기 좋습니다.
    
- **모델 크기와의 상관관계:** 일반적으로 일정 규모 이상의 매개변수(Parameter)를 가진 모델에서 효과가 극대화되는 '창발적 능력(Emergent abilities)' 중 하나로 알려져 있습니다.
    

---

## 4. 한계점

- **추론 비용 증가:** 중간 과정을 생성하는 만큼 출력 토큰 수가 늘어나 비용과 시간이 더 소요됩니다.
    
- **논리 오류의 전파:** 만약 중간 추론 단계에서 계산 실수나 논리 비약이 발생하면, 최종 정답도 틀리게 됩니다. (이를 보완하기 위해 여러 개의 추론 경로를 만들고 투표하는 **Self-Consistency** 기법 등이 함께 쓰입니다.)
    

혹시 특정 분야(코딩, 수학, 비즈니스 전략 등)에서 CoT를 활용하는 구체적인 프롬프트 예시가 필요하신가요?