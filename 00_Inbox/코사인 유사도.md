**코사인 유사도(Cosine Similarity)**는 두 벡터 사이의 각도의 코사인 값을 이용하여 **두 벡터가 얼마나 유사한지**를 측정하는 지표입니다. 주로 텍스트 마이닝, 추천 시스템, 이미지 검색 등에서 데이터 간의 유사성을 비교할 때 널리 사용됩니다.

---

## 1. 핵심 개념

코사인 유사도는 두 벡터의 크기(절댓값)보다는 **벡터가 가리키는 방향**에 집중합니다.

- **값의 범위:** $-1$에서 $1$ 사이의 값을 가집니다. (데이터가 모두 양수인 텍스트 데이터 등에서는 $0$~$1$ 사이)
    
- **유사도 판단:**
    
    - **1 (각도 0°):** 두 벡터의 방향이 완전히 일치함 (매우 유사)
        
    - **0 (각도 90°):** 두 벡터가 서로 독립적임 (관련 없음)
        
    - **-1 (각도 180°):** 두 벡터의 방향이 완전히 반대임 (매우 다름)
        

---

## 2. 수학적 정의

두 벡터 $A$와 $B$에 대한 코사인 유사도는 두 벡터의 **내적**을 각 벡터의 **크기의 곱**으로 나누어 구합니다.

$$\text{similarity} = \cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}$$

- $A \cdot B$: 두 벡터의 내적
    
- $\|A\|, \|B\|$: 각 벡터의 크기(L2 Norm)
    

---

## 3. 특징 및 장단점

|**특징**|**내용**|
|---|---|
|**방향성 강조**|벡터의 길이나 크기가 달라도 방향만 같다면 유사도가 1로 나옵니다.|
|**희소 데이터에 강점**|텍스트 데이터처럼 대부분의 값이 0인 '희소 행렬(Sparse Matrix)' 분석에 효율적입니다.|
|**비교 대상**|**유클리드 거리**는 점 사이의 물리적 거리를 보지만, **코사인 유사도**는 상대적인 패턴과 방향을 봅니다.|

---

## 4. 주요 활용 분야

- **검색 시스템:** 사용자의 검색어 벡터와 문서 벡터 간의 유사도를 측정하여 순위를 매깁니다.
    
- **추천 시스템:** 사용자들의 구매 이력이나 선호도 벡터를 비교하여 유사한 취향의 사용자나 아이템을 추천합니다.
    
- **자연어 처리(NLP):** 단어를 벡터로 변환(Word Embedding)한 후, 단어 간의 의미적 유사성을 파악할 때 사용합니다.
    

코사인 유사도를 파이썬 코드로 계산하는 방법이나, 유클리드 거리와의 구체적인 차이점이 궁금하신가요?