**Ollama(올라마)**는 사용자의 로컬 환경(내 컴퓨터)에서 대규모 언어 모델(LLM)을 아주 쉽고 간편하게 설치하고 실행할 수 있도록 도와주는 **오픈소스 도구**입니다.

보통 ChatGPT나 Claude 같은 AI는 기업의 서버에 접속해서 사용해야 하지만, Ollama를 사용하면 내 컴퓨터의 자원을 활용해 인터넷 연결 없이도 AI 모델을 구동할 수 있습니다.

---

### ## 주요 특징

- **간편한 설치 및 실행**: 복잡한 설정 없이 명령어 한 줄(`ollama run llama3` 등)로 최신 오픈소스 모델을 내려받고 바로 대화할 수 있습니다.
    
- **다양한 모델 지원**: Meta의 **Llama 3**, Google의 **Gemma**, Mistral, Phi-3 등 검증된 고성능 오픈소스 모델들을 지원합니다.
    
- **개인정보 보호**: 모든 연산이 내 컴퓨터 내에서 이루어지기 때문에 데이터가 외부 서버로 전송되지 않습니다. 보안이 중요한 작업에 유리합니다.
    
- **경량화 및 최적화**: GPU 가속을 자동으로 설정해주며, 모델 크기를 줄인 양자화(Quantization) 버전을 제공하여 일반적인 사양의 PC나 Mac에서도 부드럽게 돌아갑니다.
    
- **API 제공**: 로컬 서버 형태로 동작하기 때문에, 개발자가 직접 만든 애플리케이션이나 다른 도구(예: Obsidian, 웹 인터페이스 등)와 연동하기 매우 쉽습니다.
    

### ### 지원 운영체제

- **macOS**, **Linux**, **Windows**를 모두 지원합니다. 특히 Mac(Apple Silicon) 환경에서 최적화가 매우 잘 되어 있는 것으로 유명합니다.
    

### ### 사용 예시 (CLI 기준)

설치 후 터미널(또는 명령 프롬프트)에서 아래와 같이 입력하면 즉시 AI와 대화가 시작됩니다.

Bash

```
ollama run llama3
```
